{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd965903",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import machine_learning as ml\n",
    "import feature_extraction as fe\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as re\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# col1, col2 = st.columns([1, 3])\n",
    "\n",
    "st.title('Phishing Website Detection using Machine Learning')\n",
    "st.write('This ML-based app is developed for educational purposes. Objective of the app is detecting phishing websites only using content data. Not URL!'\n",
    "         ' You can see the details of approach, data set, and feature set if you click on _\"See The Details\"_. ')\n",
    "\n",
    "\n",
    "with st.expander(\"PROJECT DETAILS\"):\n",
    "    st.subheader('Approach')\n",
    "    st.write('I used _supervised learning_ to classify phishing and legitimate websites. '\n",
    "             'I benefit from content-based approach and focus on html of the websites. '\n",
    "             'Also, I used scikit-learn for the ML models.'\n",
    "             )\n",
    "    st.write('For this educational project, '\n",
    "             'I created my own data set and defined features, some from the literature and some based on manual analysis. '\n",
    "             'I used requests library to collect data, BeautifulSoup module to parse and extract features. ')\n",
    "    st.write('The source code and data sets are available in the below Github link:')\n",
    "    st.write('_https://github.com/emre-kocyigit/phishing-website-detection-content-based_')\n",
    "\n",
    "    st.subheader('Data set')\n",
    "    st.write('I used _\"phishtank.org\"_ & _\"tranco-list.eu\"_ as data sources.')\n",
    "    st.write('Totally 26584 websites ==> **_16060_ legitimate** websites | **_10524_ phishing** websites')\n",
    "    st.write('Data set was created in October 2022.')\n",
    "\n",
    "    # ----- FOR THE PIE CHART ----- #\n",
    "    labels = 'phishing', 'legitimate'\n",
    "    phishing_rate = int(ml.phishing_df.shape[0] / (ml.phishing_df.shape[0] + ml.legitimate_df.shape[0]) * 100)\n",
    "    legitimate_rate = 100 - phishing_rate\n",
    "    sizes = [phishing_rate, legitimate_rate]\n",
    "    explode = (0.1, 0)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.pie(sizes, explode=explode, labels=labels, shadow=True, startangle=90, autopct='%1.1f%%')\n",
    "    ax.axis('equal')\n",
    "    st.pyplot(fig)\n",
    "    # ----- !!!!! ----- #\n",
    "\n",
    "    st.write('Features + URL + Label ==> Dataframe')\n",
    "    st.markdown('label is 1 for phishing, 0 for legitimate')\n",
    "    number = st.slider(\"Select row number to display\", 0, 100)\n",
    "    st.dataframe(ml.legitimate_df.head(number))\n",
    "\n",
    "\n",
    "    @st.cache\n",
    "    def convert_df(df):\n",
    "        # IMPORTANT: Cache the conversion to prevent computation on every rerun\n",
    "        return df.to_csv().encode('utf-8')\n",
    "\n",
    "    csv = convert_df(ml.df)\n",
    "\n",
    "    st.download_button(\n",
    "        label=\"Download data as CSV\",\n",
    "        data=csv,\n",
    "        file_name='phishing_legitimate_structured_data.csv',\n",
    "        mime='text/csv',\n",
    "    )\n",
    "\n",
    "    st.subheader('Features')\n",
    "    st.write('I used only content-based features. I didn\\'t use url-based faetures like length of url etc.'\n",
    "             'Most of the features extracted using find_all() method of BeautifulSoup module after parsing html.')\n",
    "\n",
    "    st.subheader('Results')\n",
    "    st.write('I used 7 different ML classifiers of scikit-learn and tested them implementing k-fold cross validation.'\n",
    "             'Firstly obtained their confusion matrices, then calculated their accuracy, precision and recall scores.'\n",
    "             'Comparison table is below:')\n",
    "    st.table(ml.df_results)\n",
    "    st.write('NB --> Gaussian Naive Bayes')\n",
    "    st.write('SVM --> Support Vector Machine')\n",
    "    st.write('DT --> Decision Tree')\n",
    "    st.write('RF --> Random Forest')\n",
    "    st.write('AB --> AdaBoost')\n",
    "    st.write('NN --> Neural Network')\n",
    "    st.write('KN --> K-Neighbours')\n",
    "\n",
    "with st.expander('EXAMPLE PHISHING URLs:'):\n",
    "    st.write('_https://rtyu38.godaddysites.com/_')\n",
    "    st.write('_https://karafuru.invite-mint.com/_')\n",
    "    st.write('_https://defi-ned.top/h5/#/_')\n",
    "    st.caption('REMEMBER, PHISHING WEB PAGES HAVE SHORT LIFECYCLE! SO, THE EXAMPLES SHOULD BE UPDATED!')\n",
    "\n",
    "choice = st.selectbox(\"Please select your machine learning model\",\n",
    "                 [\n",
    "                     'Gaussian Naive Bayes', 'Support Vector Machine', 'Decision Tree', 'Random Forest',\n",
    "                     'AdaBoost', 'Neural Network', 'K-Neighbours'\n",
    "                 ]\n",
    "                )\n",
    "\n",
    "model = ml.nb_model\n",
    "\n",
    "if choice == 'Gaussian Naive Bayes':\n",
    "    model = ml.nb_model\n",
    "    st.write('GNB model is selected!')\n",
    "elif choice == 'Support Vector Machine':\n",
    "    model = ml.svm_model\n",
    "    st.write('SVM model is selected!')\n",
    "elif choice == 'Decision Tree':\n",
    "    model = ml.dt_model\n",
    "    st.write('DT model is selected!')\n",
    "elif choice == 'Random Forest':\n",
    "    model = ml.rf_model\n",
    "    st.write('RF model is selected!')\n",
    "elif choice == 'AdaBoost':\n",
    "    model = ml.ab_model\n",
    "    st.write('AB model is selected!')\n",
    "elif choice == 'Neural Network':\n",
    "    model = ml.nn_model\n",
    "    st.write('NN model is selected!')\n",
    "else:\n",
    "    model = ml.kn_model\n",
    "    st.write('KN model is selected!')\n",
    "\n",
    "\n",
    "url = st.text_input('Enter the URL')\n",
    "# check the url is valid or not\n",
    "if st.button('Check!'):\n",
    "    try:\n",
    "        response = re.get(url, verify=False, timeout=4)\n",
    "        if response.status_code != 200:\n",
    "            print(\". HTTP connection was not successful for the URL: \", url)\n",
    "        else:\n",
    "            soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "            vector = [fe.create_vector(soup)]  # it should be 2d array, so I added []\n",
    "            result = model.predict(vector)\n",
    "            if result[0] == 0:\n",
    "                st.success(\"This web page seems a legitimate!\")\n",
    "                st.balloons()\n",
    "            else:\n",
    "                st.warning(\"Attention! This web page is a potential PHISHING!\")\n",
    "                st.snow()\n",
    "\n",
    "    except re.exceptions.RequestException as e:\n",
    "        print(\"--> \", e)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
